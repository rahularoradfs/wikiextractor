{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_new_dumps = True # set to False if you have up-to-date dumps\n",
    "\n",
    "# do you want to extract the dumps? set to True if yes\n",
    "# set to False if you want to extract the XML dump page-by-page, or already have extracted the dumps\n",
    "extract_dumps = True "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and process Wikipedia XML dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to latest dump\n",
    "LATEST_WP_DUMP_WEB = 'https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2'\n",
    "LATEST_WP_DUMP_LOCAL = 'enwiki-latest-pages-articles.xml.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-03 09:16:56--  https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2\n",
      "Resolving dumps.wikimedia.org (dumps.wikimedia.org)... 2620:0:861:2:208:80:154:142, 208.80.154.142\n",
      "Connecting to dumps.wikimedia.org (dumps.wikimedia.org)|2620:0:861:2:208:80:154:142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20680789666 (19G) [application/octet-stream]\n",
      "Saving to: 'enwiki-latest-pages-articles.xml.bz2'\n",
      "\n",
      "est-pages-articles.   0%[                    ]  65.16M  3.84MB/s    eta 78m 24s^C\n"
     ]
    }
   ],
   "source": [
    "# get most recent wikipedia dump\n",
    "if download_new_dumps:\n",
    "    print('Downloading latest Wikipedia dump...')\n",
    "    subprocess.run(['rm', LATEST_WP_DUMP_LOCAL])\n",
    "    subprocess.call(['wget', LATEST_WP_DUMP_WEB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process most recent wikipedia dump\n",
    "\n",
    "if extract_dumps:\n",
    "    print('Extracting Wikipedia dump...')\n",
    "\n",
    "    output_dir = 'wp_extracts'\n",
    "    subprocess.run(['rm -rf', output_dir])\n",
    "    subprocess.run(['mkdir', output_dir])\n",
    "\n",
    "    templates_file = 'xml_templates.txt'\n",
    "    subprocess.run(['rm', templates_file])\n",
    "\n",
    "    args = [\n",
    "        'python3', 'wikiextractor/WikiExtractor.py',\n",
    "        '--output', output_dir,\n",
    "        # '--json',\n",
    "        '--templates', templates_file,\n",
    "        LATEST_WP_DUMP_LOCAL\n",
    "    ]\n",
    "    completed_process = subprocess.run(args)\n",
    "\n",
    "    if completed_process.returncode != 0:\n",
    "        raise Exception(f'WikiExtractor.py exited with code {completed_process.returncode}')\n",
    "    else:\n",
    "        print(f'WikiExtractor.py completed successfully. Saved results to {output_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract single article from wp dump\n",
    "\n",
    "if extract_dumps:\n",
    "    print('Extracting test page from Wikipedia dump...')\n",
    "    args = [\n",
    "        'python3', 'wikiextractor/extractPage.py',\n",
    "        '--id', '100',\n",
    "        LATEST_WP_DUMP_LOCAL\n",
    "    ]\n",
    "    completed_process = subprocess.run(args)\n",
    "\n",
    "    if completed_process.returncode != 0:\n",
    "        raise Exception(f'ExtractPage.py exited with code {completed_process.returncode}')\n",
    "    else:\n",
    "        print(f'ExtractPage.py completed successfully.')\n",
    "\n",
    "    completed_process.stdout"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get and process Cirrus dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enwiki-20230227-cirrussearch-general.json.gz\n"
     ]
    }
   ],
   "source": [
    "# get path to most recent cirrus dump\n",
    "LATEST_CIRRUS_DUMP_STDOUT = !curl https://dumps.wikimedia.org/other/cirrussearch/current/ | grep -o 'enwiki-[0-9]*-cirrussearch-general.json.gz' | sort -r | head -n 1\n",
    "LATEST_CIRRUS_DUMP_WEB = LATEST_CIRRUS_DUMP_STDOUT[-1]\n",
    "LATEST_CIRRUS_DUMP_LOCAL = 'enwiki-latest-cirrussearch-general.json.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-03 09:24:56--  https://dumps.wikimedia.org/other/cirrussearch/current/enwiki-20230227-cirrussearch-general.json.gz\n",
      "Resolving dumps.wikimedia.org (dumps.wikimedia.org)... 2620:0:861:2:208:80:154:142, 208.80.154.142\n",
      "Connecting to dumps.wikimedia.org (dumps.wikimedia.org)|2620:0:861:2:208:80:154:142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 53475861433 (50G) [application/octet-stream]\n",
      "Saving to: 'enwiki-20230227-cirrussearch-general.json.gz'\n",
      "\n",
      ".json.gz              8%[>                   ]   4.13G  3.94MB/s    eta 3h 30m ^C\n"
     ]
    }
   ],
   "source": [
    "# get that dump\n",
    "if download_new_dumps:\n",
    "    print('Downloading latest Cirrus dump...')\n",
    "    subprocess.run(['rm', LATEST_CIRRUS_DUMP_LOCAL])\n",
    "    suprocess.run(['wget', f'https://dumps.wikimedia.org/other/cirrussearch/current/{LATEST_CIRRUS_DUMP_WEB}'])\n",
    "    subprocess.run(['mv', LATEST_CIRRUS_DUMP_WEB, LATEST_CIRRUS_DUMP_LOCAL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process most recent Cirrus dump\n",
    "\n",
    "output_dir = 'cirrus_extracts'\n",
    "subprocess.run(['rm -rf', output_dir])\n",
    "subprocess.run(['mkdir', output_dir])\n",
    "\n",
    "args = [\n",
    "    'python3', 'wikiextractor/cirrus-extract.py',\n",
    "    '--output', output_dir,\n",
    "    LATEST_CIRRUS_DUMP_LOCAL\n",
    "]\n",
    "completed_process = subprocess.run(args)\n",
    "\n",
    "if completed_process.returncode != 0:\n",
    "    raise Exception(f'cirrus-extract.py exited with code {completed_process.returncode}')\n",
    "else:\n",
    "    print(f'cirrus-extract.py completed successfully. Saved results to {output_dir}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19f12dad191d2054919ec10ea33eb2fc0c3027858b4fd481d883888f1808c1b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
